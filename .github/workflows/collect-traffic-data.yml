# .github/workflows/collect-traffic-data.yml
name: Hyderabad Traffic Data Collection

on:
  schedule:
    # Run every 10 minutes indefinitely
    - cron: '*/10 * * * *' # Changed from '*/1 * * * *'
  workflow_dispatch:
    inputs:
      duration_minutes:
        description: 'Total duration for data collection loop (minutes)'
        required: false
        default: '4' # Default for manual trigger
        type: string # Using string as fallback logic handles empty string for scheduled runs
      collection_interval:
        description: 'Interval between each data collection (minutes)'
        required: false
        default: '1' # Default for manual trigger
        type: string # Using string as fallback logic handles empty string for scheduled runs

jobs:
  collect-traffic-data:
    runs-on: ubuntu-latest
    # Set a timeout that can comfortably accommodate the maximum expected duration
    # For a 4-hour default (240 mins) + buffer, 260 mins is reasonable.
    # Adjust this if you anticipate much longer manual runs.
    timeout-minutes: 260 # Increased to allow for longer manual runs (e.g., 4 hours)
    permissions:
      contents: write # Required to push changes back to repository

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      # GITHUB_TOKEN is usually available by default, explicit passing is fine.
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip' # Caches pip dependencies for faster subsequent runs

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create data directory
      run: mkdir -p data # -p ensures directory is created if it doesn't exist

    - name: Run traffic data collection in loop
      env:
        Maps_API_KEY: ${{ secrets.Maps_API_KEY }}
      run: |
        # Determine duration and interval.
        # For 'schedule' runs, github.event.inputs will be empty, so use defaults.
        # For 'workflow_dispatch' runs, use the provided inputs.
        
        # Use a default for scheduled runs (e.g., 10 minutes duration with 1 minute interval)
        # This makes sense if your scheduled run should perform a quick "snapshot"
        # rather than a long continuous collection.
        # If the scheduled run should behave like the manual default (4 hours, 1 min interval),
        # then set the scheduled_defaults to 240 and 1.
        scheduled_default_duration=10
        scheduled_default_interval=1

        # Check if inputs are provided (i.e., triggered by workflow_dispatch)
        if [ -n "${{ github.event.inputs.duration_minutes }}" ]; then
          duration="${{ github.event.inputs.duration_minutes }}"
        else
          duration="$scheduled_default_duration"
        fi

        if [ -n "${{ github.event.inputs.collection_interval }}" ]; then
          interval="${{ github.event.inputs.collection_interval }}"
        else
          interval="$scheduled_default_interval"
        fi

        # Convert to integers for arithmetic
        duration_int=$((duration))
        interval_int=$((interval))

        # Basic validation to prevent infinite loops or division by zero
        if [ "$interval_int" -le 0 ]; then
          echo "Error: collection_interval must be a positive number."
          exit 1
        fi
        if [ "$duration_int" -le 0 ]; then
          echo "Warning: duration_minutes is zero or negative. No data collection will occur."
          exit 0
        fi

        echo "ðŸ“Š Starting traffic data collection for ${duration_int} minutes at every ${interval_int} minutes."

        iterations=$((duration_int / interval_int))
        remainder=$((duration_int % interval_int)) # Handle cases where duration isn't a perfect multiple
        
        # If duration is less than interval, run once and then exit
        if [ "$iterations" -eq 0 ] && [ "$duration_int" -gt 0 ]; then
            iterations=1
        fi

        for ((i=1; i<=iterations; i++))
        do
          echo "ðŸš¦ Run $i of $iterations - Collecting data..."
          python traffic_analyzer.py # Your script to collect data
          
          # Only sleep if it's not the last iteration AND there's actual time left to sleep
          if [ $i -lt $iterations ]; then
            echo "â± Sleeping for ${interval_int} minutes..."
            sleep $((interval_int * 60))
          elif [ $remainder -gt 0 ]; then
            # If there's a remainder, sleep for that remaining time after the last full interval run
            echo "â± Sleeping for remaining ${remainder} minutes..."
            sleep $((remainder * 60))
          fi
        done
        echo "âœ… Data collection loop finished."

    - name: Check for data files
      run: |
        echo "Checking for generated data files..."
        # Using find to be more robust for files potentially in subdirectories of data/
        find . -maxdepth 2 -type f -name "*.csv" || echo "No CSV files found."

    - name: Commit and push data
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

        # Add any CSV files that were created, allowing for direct root or data/ directory
        find . -maxdepth 2 -type f -name "*.csv" -exec git add {} +

        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "No new data files to commit."
        else
          git commit -m "Add traffic data - $(date '+%Y-%m-%d %H:%M:%S UTC')"
          echo "Committing and pushing new data files."
          git push
        fi

    - name: Upload data as artifact
      uses: actions/upload-artifact@v4
      if: always() # Ensure artifact is uploaded even if previous steps fail
      with:
        name: traffic-data-${{ github.run_number }}
        path: |
          *.csv # Include CSVs in root
          data/*.csv # Include CSVs in data directory
        retention-days: 30 # Data will be available for 30 days
